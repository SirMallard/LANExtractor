{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Dictionaries into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LANoireTools.newscripts.dictionaries import FILE_FULLNAME_DICTIONARY\n",
    "from json import dump\n",
    "\n",
    "with open(\"name_hashes.json\", \"w\") as file:\n",
    "\tdump({\n",
    "\t\t\"file_name_hashes\": FILE_FULLNAME_DICTIONARY\n",
    "\t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import decompress\n",
    "\n",
    "IN_FILE = \"X:\\\\SteamLibrary\\\\steamapps\\\\common\\\\L.A.Noire\\\\final\\\\pc\\\\cases.big.pc\"\n",
    "# IN_FILE = \"..\\\\dump\\\\out\\\\files\\\\out\\\\trunk\\\\models\\\\la\\\\environment\\\\weather\\\\sun.trunk.pc\"\n",
    "OUT_FILE = \"out2.unk\"\n",
    "OFFSET = 463264\n",
    "SIZE = 32704 # - OFFSET\n",
    "COMPRESSED = True\n",
    "\n",
    "with open(IN_FILE, \"rb\") as file:\n",
    "\tfile.seek(OFFSET)\n",
    "\twith open(OUT_FILE, \"wb\") as out:\n",
    "\t\tdata: bytes = file.read(SIZE)\n",
    "\t\tif COMPRESSED:\n",
    "\t\t\tdata = decompress(data, -15)\n",
    "\t\tout.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"..\\\\dump\\\\vehicles\\\\files\\\\intermediate\\\\chunks\\\\vehicles\\\\\"\n",
    "FILES = [\"ford_2dr_1947.chunk\", \"services\\\\ford_4dr_1947_police_vehicle.chunk\", \"chrysler_town_n_country_1946.chunk\", \"cadillac_ser_61_1947.chunk\"]\n",
    "\n",
    "RANGE = 144\n",
    "\n",
    "out = [\"\"] * (RANGE // 4)\n",
    "\n",
    "for file in FILES:\n",
    "\twith open(PATH + file, \"rb\") as car:\n",
    "\t\tdata: str = car.read(RANGE).hex()\n",
    "\t\tfor i in range(RANGE // 4):\n",
    "\t\t\tout[i] += data[8 * i : 8 * (i + 1)] + \"\\t\"\n",
    "\n",
    "for s in out:\n",
    "\tprint(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import dirname, join\n",
    "from struct import unpack\n",
    "from json import dump\n",
    "\n",
    "# FILE_NAME = \"examples/cases.big.pc\"\n",
    "# FILE_NAME = \"examples/audio.big.pc\"\n",
    "FILE_NAME = \"examples/out.wad.pc\"\n",
    "OUT_FILE = \"file_data.json\"\n",
    "OUT_DIRECTORY = \"dump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import IOBase\n",
    "\n",
    "class FileStream():\n",
    "\tdef __init__(self, file: IOBase):\n",
    "\t\tself._file = file\n",
    "\t\tself._endian = \"@\"\n",
    "\n",
    "\tdef set_endian(self, endian: str):\n",
    "\t\tself._endian = endian\n",
    "\n",
    "\tdef tell(self):\n",
    "\t\treturn self._file.tell()\n",
    "\n",
    "\tdef seek(self, offset: int, end: int):\n",
    "\t\tself._file.seek(offset, end)\n",
    "\n",
    "\tdef read(self, format: str, length: int):\n",
    "\t\treturn unpack(f\"{self._endian}{format}\", self._file.read(length))[0]\n",
    "\n",
    "\tdef read_uint8(self):\n",
    "\t\treturn self.read(\"B\", 1)\n",
    "\t\t\n",
    "\tdef read_int8(self):\n",
    "\t\treturn self.read(\"b\", 1)\n",
    "\t\t\n",
    "\tdef read_uint16(self):\n",
    "\t\treturn self.read(\"H\", 2)\n",
    "\t\t\n",
    "\tdef read_int16(self):\n",
    "\t\treturn self.read(\"h\", 2)\n",
    "\n",
    "\tdef read_uint32(self):\n",
    "\t\treturn self.read(\"I\", 4)\n",
    "\t\t\n",
    "\tdef read_int32(self):\n",
    "\t\treturn self.read(\"i\", 4)\n",
    "\t\t\n",
    "\tdef read_uint64(self):\n",
    "\t\treturn self.read(\"Q\", 8)\n",
    "\t\t\n",
    "\tdef read_int64(self):\n",
    "\t\treturn self.read(\"q\", 8)\n",
    "\n",
    "\tdef read_float32(self):\n",
    "\t\treturn self.read(\"f\", 4)\n",
    "\t\t\n",
    "\tdef read_float64(self):\n",
    "\t\treturn self.read(\"d\", 8)\n",
    "\n",
    "\tdef read_string(self, length: int):\n",
    "\t\treturn self.read(f\"{length}s\", length)\n",
    "\n",
    "\tdef read_pad(self, length: int):\n",
    "\t\tself.read_chunk(length)\n",
    "\n",
    "\tdef read_chunk(self, length: int):\n",
    "\t\treturn self._file.read(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIG Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_NAME, \"rb\") as big:\n",
    "\tstream = FileStream(big)\n",
    "\tstream.seek(-4, 2)\n",
    "\n",
    "\tprint(\"Pos:\", hex(stream.tell()))\n",
    "\tsize = stream.read_uint32()\n",
    "\tprint(\"Size:\", size, hex(size))\n",
    "\tprint(\"Pos:\", hex(stream.tell()))\n",
    "\n",
    "\tstream.seek(-size, 2)\n",
    "\tstream.read_pad(0x4)\n",
    "\n",
    "\tprint(\"Pos:\", hex(stream.tell()))\n",
    "\tnum_files = stream.read_uint32()\n",
    "\tprint(\"Files:\", num_files, hex(num_files))\n",
    "\tprint(\"Pos:\", hex(stream.tell()))\n",
    "\tprint()\n",
    "\n",
    "\tfile_data = [None] * num_files\n",
    "\n",
    "\tprint(num_files)\n",
    "\tfor i in range(num_files):\n",
    "\t\thash = stream.read_uint32()\n",
    "\t\toffset = stream.read_uint32()\n",
    "\t\tsize = stream.read_uint32()\n",
    "\t\tstream.read_pad(4)\n",
    "\t\txsize = stream.read_uint32()\n",
    "\t\toffset *= 0x10\n",
    "\t\tfile_data[i] = [hash, offset, size, xsize]\n",
    "\n",
    "\tfor i in range(num_files):\n",
    "\t\tpass\n",
    "\n",
    "\t# stream.seek(-4, 2)\n",
    "\t# print(\"Pos:\", hex(stream.tell()))\n",
    "\t# table_offset = unpack(\"<I\", big.read(4))[0]\n",
    "\t# file_offset = table_offset - 0xC\n",
    "\t# size_offset = table_offset - 0x10\n",
    "\t# print(\"Size:\", size_offset, hex(size_offset))\n",
    "\t# print(\"Pos:\", hex(stream.tell()))\n",
    "\n",
    "\t# big.seek(-size_offset, 2)\n",
    "\n",
    "\t# print(\"Pos:\", hex(stream.tell()))\n",
    "\t# size = unpack(\"<I\", big.read(4))[0]\n",
    "\t# print(\"Files:\", size, hex(num_files))\n",
    "\t# print(\"Pos:\", hex(stream.tell()))\n",
    "\n",
    "\t# print(size)\n",
    "\t# big.seek(4, 1)\n",
    "\t# raw_size = unpack(\"<I\", big.read(4))[0]\n",
    "\t# big.seek(-file_offset, 2)\n",
    "\t# offset = unpack(\"<I\", big.read(4))[0] * 0x10\n",
    "\n",
    "\t# print(size, raw_size, offset)\n",
    "\n",
    "\t# big.seek(offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAD Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_NAME, \"rb\") as wad:\n",
    "\tstream: FileStream = FileStream(wad)\n",
    "\n",
    "\tsign = stream.read_string(3)\n",
    "\tstream.read_pad(1)\n",
    "\tnum_files = stream.read_uint32()\n",
    "\t\n",
    "\tfile_data = [None] * num_files\n",
    "\tnames_offset = 0\n",
    "\n",
    "\tfor i in range(num_files):\n",
    "\t\thash = stream.read_uint32()\n",
    "\t\toffset = stream.read_uint32()\n",
    "\t\tsize = stream.read_uint32()\n",
    "\t\tnames_offset = max(offset + size, names_offset)\n",
    "\t\tfile_data[i] = [hash, offset, size]\n",
    "\n",
    "\t\tprint(hex(offset))\n",
    "\n",
    "\tstream.seek(names_offset, 0)\n",
    "\tfor i in range(num_files):\n",
    "\t\tname_len = stream.read_uint16()\n",
    "\t\tname = stream.read_string(name_len).decode(\"utf-8\")\n",
    "\t\tfile_data[i].append(name_len)\n",
    "\t\tfile_data[i].append(name)\n",
    "\t\toffset = file_data[i][1]\n",
    "\t\tsize = file_data[i][2]\n",
    "\n",
    "\t\t# position = stream.tell()\n",
    "\n",
    "\t\t# stream.seek(offset, 0)\n",
    "\t\t# makedirs(join(OUT_DIRECTORY, dirname(name)), exist_ok = True)\n",
    "\t\t# with open(join(OUT_DIRECTORY, name), \"wb\") as data_file:\n",
    "\t\t# \tdata_file.write(stream.read_chunk(size))\n",
    "\n",
    "\t\t# stream.seek(position, 0)\n",
    "\n",
    "\n",
    "# with open(join(OUT_DIRECTORY, FILE_NAME.split(\".\")[0], OUT_FILE), \"w\") as file:\n",
    "# \tdump(file_data, file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"X:\\\\SteamLibrary\\\\steamapps\\\\common\\\\L.A.Noire\"\n",
    "\n",
    "from os import walk\n",
    "from os.path import join\n",
    "\n",
    "for root, dirs, files in walk(DIRECTORY, ):\n",
    "\tif \"Mods\" in root:\n",
    "\t\tcontinue\n",
    "\tfor file in files:\n",
    "\t\twith open(\"out.xml\", \"a\") as f:\n",
    "\t\t\tf.write(f\"\\t<GameFile Name=\\\"{join(root, file).lstrip(DIRECTORY)}\\\" />\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
